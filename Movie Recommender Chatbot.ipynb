{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":127736,"sourceType":"datasetVersion","datasetId":64890}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Install Dependencies & Import Library**","metadata":{}},{"cell_type":"code","source":"!pip install -q sentence-transformers faiss-cpu groq requests nltk","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-15T16:31:19.597880Z","iopub.execute_input":"2025-11-15T16:31:19.598247Z","iopub.status.idle":"2025-11-15T16:32:31.995439Z","shell.execute_reply.started":"2025-11-15T16:31:19.598223Z","shell.execute_reply":"2025-11-15T16:32:31.994525Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport re\nimport requests\nimport pandas as pd\nimport numpy as np\nimport faiss\nfrom sentence_transformers import SentenceTransformer\nimport nltk\nfrom nltk.tokenize import sent_tokenize","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T16:32:31.997274Z","iopub.execute_input":"2025-11-15T16:32:31.997505Z","iopub.status.idle":"2025-11-15T16:33:04.657247Z","shell.execute_reply.started":"2025-11-15T16:32:31.997482Z","shell.execute_reply":"2025-11-15T16:33:04.656668Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Load API Keys**","metadata":{}},{"cell_type":"code","source":"from groq import Groq\nfrom kaggle_secrets import UserSecretsClient\n\n# Load secrets dari Kaggle\nuser_secrets = UserSecretsClient()\nGROQ_API_KEY = user_secrets.get_secret(\"GROQ_API_KEY\")\nSERPER_API_KEY = user_secrets.get_secret(\"SERPER_API_KEY\")\n\nclient = Groq(api_key=GROQ_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T16:33:04.657897Z","iopub.execute_input":"2025-11-15T16:33:04.658486Z","iopub.status.idle":"2025-11-15T16:33:05.586619Z","shell.execute_reply.started":"2025-11-15T16:33:04.658459Z","shell.execute_reply":"2025-11-15T16:33:05.585860Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Load & Cleaning Dataset**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/wikipedia-movie-plots/wiki_movie_plots_deduped.csv\")\n\ndf = df.rename(columns={\n    \"Title\": \"title\",\n    \"Release Year\": \"year\",\n    \"Origin/Ethnicity\": \"origin\",\n    \"Director\": \"director\",\n    \"Cast\": \"cast\",\n    \"Genre\": \"genre\",\n    \"Wiki Page\": \"link\",\n    \"Plot\": \"plot\"\n})\n\ndf[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\").astype(\"Int64\")\n\ndf = df.fillna(\"Unknown\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T16:33:05.587417Z","iopub.execute_input":"2025-11-15T16:33:05.587681Z","iopub.status.idle":"2025-11-15T16:33:07.965448Z","shell.execute_reply.started":"2025-11-15T16:33:05.587657Z","shell.execute_reply":"2025-11-15T16:33:07.964625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_cleaned = df.copy()\ndf_cleaned = df_cleaned.dropna(subset=[\"title\", \"plot\"])\ndf_cleaned = df_cleaned.drop_duplicates(subset=[\"title\", \"year\"])\n\ncols_to_fill = [\"origin\", \"director\", \"cast\", \"genre\", \"link\"]\nfor c in cols_to_fill:\n    df_cleaned[c] = df_cleaned[c].fillna(\"Unknown\")\n\nprint(f\"Total baris sebelum cleaning: {len(df):,}\")\nprint(f\"Total baris setelah cleaning: {len(df_cleaned):,}\")\nprint(f\"Total data yang dihapus: {len(df) - len(df_cleaned):,}\\n\")\n\nprint(\"Missing value per kolom:\")\nprint(df_cleaned.isnull().sum(), \"\\n\")\n\ndisplay(df_cleaned.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T16:33:07.967282Z","iopub.execute_input":"2025-11-15T16:33:07.967866Z","iopub.status.idle":"2025-11-15T16:33:08.040250Z","shell.execute_reply.started":"2025-11-15T16:33:07.967846Z","shell.execute_reply":"2025-11-15T16:33:08.039438Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Chunking**","metadata":{}},{"cell_type":"code","source":"def split_plot_into_chunks(text, max_words=150, overlap=30):\n    if not isinstance(text, str) or not text.strip():\n        return []\n\n    words = text.split()\n    chunks = []\n\n    i = 0\n    while i < len(words):\n        chunk_words = words[i:i + max_words]\n        chunks.append(\" \".join(chunk_words))\n        i += max_words - overlap\n\n    return chunks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T16:33:08.041120Z","iopub.execute_input":"2025-11-15T16:33:08.041451Z","iopub.status.idle":"2025-11-15T16:33:08.046128Z","shell.execute_reply.started":"2025-11-15T16:33:08.041424Z","shell.execute_reply":"2025-11-15T16:33:08.045477Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"docs = []\nmetas = []\n\nfor i, row in df_cleaned.iterrows():\n\n    title   = str(row[\"title\"]).strip()\n    year    = int(row[\"year\"])\n    origin  = str(row[\"origin\"]).strip()\n    genre   = str(row[\"genre\"]).strip()\n    director = str(row[\"director\"]).strip()\n    cast     = str(row[\"cast\"]).strip()\n    plot     = str(row[\"plot\"]).strip()\n\n    # Chunk 1: metadata pendek\n    meta_text = f\"\"\"\nTitle: {title}\nYear: {year}\nOrigin: {origin}\nGenre: {genre}\nDirector: {director}\nCast: {cast}\n\"\"\".strip()\n\n    docs.append(meta_text)\n    metas.append({\n        \"movie_id\": i,\n        \"chunk_type\": \"meta\",\n        \"title\": title,\n        \"year\": year,\n        \"origin\": origin,\n        \"genre\": genre,\n        \"director\": director,\n        \"cast\": cast\n    })\n\n    # Chunk 2: plot yg sudah di split\n    plot_chunks = split_plot_into_chunks(plot, max_words=150, overlap=30)\n\n    for ch in plot_chunks:\n        docs.append(ch)    \n        metas.append({\n            \"movie_id\": i,\n            \"chunk_type\": \"plot\",\n            \"title\": title,\n            \"year\": year,\n            \"origin\": origin,\n            \"genre\": genre,\n            \"director\": director,\n            \"cast\": cast\n        })\n\ntotal_chunks = len(docs)\ntotal_movies = len(df_cleaned)\n\nprint(f\"Total film      : {total_movies}\")\nprint(f\"Total chunk     : {total_chunks}\")\nprint(f\"Rata-rata chunk : {total_chunks / total_movies:.2f} per film\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T16:33:08.046862Z","iopub.execute_input":"2025-11-15T16:33:08.047100Z","iopub.status.idle":"2025-11-15T16:33:11.133152Z","shell.execute_reply.started":"2025-11-15T16:33:08.047048Z","shell.execute_reply":"2025-11-15T16:33:11.132498Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Load Embedding Model & Encode**","metadata":{}},{"cell_type":"code","source":"# Load embedding model\nEMB_MODEL = \"BAAI/bge-small-en-v1.5\"\nemb_model = SentenceTransformer(EMB_MODEL)\n\n# Encode semua dokumen\nembeddings = emb_model.encode(\n    docs,\n    batch_size=64,\n    show_progress_bar=True,\n    convert_to_numpy=True,\n    normalize_embeddings=True,\n)\n\n# Pastikan float32\nembeddings = embeddings.astype(\"float32\")\n\nprint(\"Embeddings shape:\", embeddings.shape)\n\nd = embeddings.shape[1]\nindex = faiss.IndexFlatIP(d)\nindex.add(embeddings)\n\nprint(\"Total vektor di index:\", index.ntotal)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T16:33:11.133955Z","iopub.execute_input":"2025-11-15T16:33:11.134230Z","iopub.status.idle":"2025-11-15T16:41:47.050408Z","shell.execute_reply.started":"2025-11-15T16:33:11.134201Z","shell.execute_reply":"2025-11-15T16:41:47.049603Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Normalization, Boosting & Search Function**","metadata":{}},{"cell_type":"code","source":"def normalize_title(text):\n    if not isinstance(text, str):\n        return \"\"\n    text = text.lower()\n    text = re.sub(r\"[^a-z0-9 ]+\", \" \", text)\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\n\ndef title_boost(query, candidates):\n    q = normalize_title(query)\n\n    for c in candidates:\n        title = normalize_title(c[\"meta\"][\"title\"])\n\n        if q == title:\n            c[\"score\"] += 5.0\n            continue\n        \n        if q in title and len(q.split()) > 1:\n            c[\"score\"] += 2.5\n            continue\n        \n        q_words = set(q.split())\n        t_words = set(title.split())\n        overlap = len(q_words & t_words)\n\n        if overlap >= 2:\n            c[\"score\"] += 1.0\n\n    return candidates","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T16:41:47.051328Z","iopub.execute_input":"2025-11-15T16:41:47.051589Z","iopub.status.idle":"2025-11-15T16:41:47.057236Z","shell.execute_reply.started":"2025-11-15T16:41:47.051565Z","shell.execute_reply":"2025-11-15T16:41:47.056566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def normalize_tokens(s):\n    s = s.lower().strip()\n    s = re.sub(r\"[^a-z0-9, /]+\", \"\", s)\n    tokens = re.split(r\"[,/ ]+\", s)\n    return [t for t in tokens if t]\n\ndef match_filter(meta, genre=None, origin=None, min_year=None, max_year=None):\n    \"\"\"Filter berdasarkan genre, origin, tahun dengan cara yang aman.\"\"\"\n\n    y = meta[\"year\"]\n    genre_tokens = normalize_tokens(meta[\"genre\"] or \"\")\n    origin_tokens = normalize_tokens(meta[\"origin\"] or \"\")\n\n    # Year filter\n    if min_year is not None and y < min_year:\n        return False\n    if max_year is not None and y > max_year:\n        return False\n\n    # Genre filter\n    if genre:\n        g = genre.lower().strip()\n        if g not in genre_tokens:\n            return False\n\n    # Origin filter\n    if origin:\n        o = origin.lower().strip()\n        if o not in origin_tokens:\n            return False\n\n    return True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T16:41:47.057869Z","iopub.execute_input":"2025-11-15T16:41:47.058069Z","iopub.status.idle":"2025-11-15T16:41:47.072890Z","shell.execute_reply.started":"2025-11-15T16:41:47.058037Z","shell.execute_reply":"2025-11-15T16:41:47.072357Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def search_chunks(query, top_k=200):\n    # embed query\n    q_emb = emb_model.encode(\n        [query], \n        convert_to_numpy=True,\n        normalize_embeddings=True\n    )\n\n    scores, idx = index.search(q_emb, top_k)\n    scores = scores[0]\n    idx = idx[0]\n\n    results = []\n    for s, i_doc in zip(scores, idx):\n        results.append({\n            \"score\": float(s),\n            \"chunk_id\": int(i_doc),\n            \"text\": docs[i_doc],\n            \"meta\": metas[i_doc],   \n        })\n\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T16:41:47.073574Z","iopub.execute_input":"2025-11-15T16:41:47.074034Z","iopub.status.idle":"2025-11-15T16:41:47.085538Z","shell.execute_reply.started":"2025-11-15T16:41:47.074012Z","shell.execute_reply":"2025-11-15T16:41:47.084938Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def search_movies(\n    query,\n    top_k_movies=5,\n    top_k_chunks=200,\n    genre=None,\n    origin=None,\n    min_year=None,\n    max_year=None,\n):\n    # Ambil chunk dari FAISS\n    chunks = search_chunks(query, top_k=top_k_chunks)\n\n    movie_map = {}  \n\n    for ch in chunks:\n        meta = ch[\"meta\"]\n        movie_id = meta[\"movie_id\"]\n\n        # Filter\n        if not match_filter(meta, genre, origin, min_year, max_year):\n            continue\n\n        # Simpan skor tertinggi per film\n        if movie_id not in movie_map or ch[\"score\"] > movie_map[movie_id][\"score\"]:\n            movie_map[movie_id] = {\n                \"movie_id\": movie_id,\n                \"score\": ch[\"score\"],\n                \"text\": ch[\"text\"],\n                \"meta\": meta,\n            }\n\n    # Jika filter kosong, pakai semua chunk (fallback)\n    if len(movie_map) == 0:\n        movie_map = {}\n        for ch in chunks:\n            meta = ch[\"meta\"]\n            movie_id = meta[\"movie_id\"]\n            if movie_id not in movie_map or ch[\"score\"] > movie_map[movie_id][\"score\"]:\n                movie_map[movie_id] = {\n                    \"movie_id\": movie_id,\n                    \"score\": ch[\"score\"],\n                    \"text\": ch[\"text\"],\n                    \"meta\": meta,\n                }\n\n    # Convert ke list\n    movie_list = list(movie_map.values())\n\n    # BOOST ranking dengan judul\n    movie_list = title_boost(query, movie_list)\n\n    # Final sorting\n    movie_list = sorted(movie_list, key=lambda x: x[\"score\"], reverse=True)\n\n    return movie_list[:top_k_movies]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T16:41:47.086240Z","iopub.execute_input":"2025-11-15T16:41:47.086411Z","iopub.status.idle":"2025-11-15T16:41:47.099203Z","shell.execute_reply.started":"2025-11-15T16:41:47.086398Z","shell.execute_reply":"2025-11-15T16:41:47.098645Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def clean_web_text(text):\n    if not text:\n        return \"\"\n    text = re.sub(r\"\\s+\", \" \", text)\n    return text.strip()\n\ndef web_search_serper(query):\n    url = \"https://google.serper.dev/search\"\n    headers = {\n        \"X-API-KEY\": SERPER_API_KEY,\n        \"Content-Type\": \"application/json\",\n    }\n    payload = {\"q\": query, \"num\": 5}\n\n    try:\n        resp = requests.post(url, json=payload, headers=headers, timeout=7)\n        data = resp.json()\n    except Exception:\n        return None\n\n    collected = []\n\n    if \"answerBox\" in data:\n        ab = data[\"answerBox\"]\n        for k in [\"answer\", \"snippet\", \"title\"]:\n            if k in ab:\n                collected.append(clean_web_text(ab[k]))\n\n    if \"knowledgeGraph\" in data:\n        kg = data[\"knowledgeGraph\"]\n        for k in [\"description\", \"type\", \"title\"]:\n            if k in kg:\n                collected.append(clean_web_text(kg[k]))\n\n    if \"organic\" in data:\n        for item in data[\"organic\"]:\n            title = clean_web_text(item.get(\"title\", \"\"))\n            snippet = clean_web_text(item.get(\"snippet\", \"\"))\n            combined = (title + \"\\n\" + snippet).strip()\n            if combined:\n                collected.append(combined)\n\n    return \"\\n\\n\".join(collected[:5]) if collected else None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T16:41:47.099871Z","iopub.execute_input":"2025-11-15T16:41:47.100120Z","iopub.status.idle":"2025-11-15T16:41:47.118865Z","shell.execute_reply.started":"2025-11-15T16:41:47.100074Z","shell.execute_reply":"2025-11-15T16:41:47.118121Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Building Chatbot**","metadata":{}},{"cell_type":"code","source":"def build_prompt(query, movies, web_context=None):\n\n    movie_blocks = []\n    for m in movies:\n        meta = m[\"meta\"]\n        block = f\"\"\"\nJudul: {meta['title']}\nTahun: {meta['year']}\nAsal: {meta['origin']}\nGenre: {meta['genre']}\nDirector: {meta['director']}\n\nRingkasan:\n{m['text']}\n\"\"\".strip()\n        movie_blocks.append(block)\n\n    ctx_movies = \"\\n\\n---\\n\\n\".join(movie_blocks)\n    ctx_web = web_context.strip() if web_context else \"\"\n\n    prompt = f\"\"\"\nKamu adalah teman ngobrol yang paham banyak film. \nGaya bicaramu santai, jelas, ringan, tidak formal, dan tidak kaku.\n\nTugasmu:\n- Jawab pertanyaan pengguna dengan santai dan natural.\n- Gunakan informasi yang tersedia dalam konteks film dan konteks web.\n- Jika ada beberapa film relevan, sebutkan 1–3 yang paling cocok dan jelasin singkat kenapa.\n- Jangan bawa info dari luar konteks.\n- Kalau infonya tidak ada, bilang saja dengan santai “nggak ada infonya nih”.\n\n========================\nKonteks Film:\n{ctx_movies}\n\n========================\nKonteks Web:\n{ctx_web}\n\n========================\nPertanyaan:\n{query}\n\nJawaban santai:\n\"\"\"\n    return prompt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T16:41:47.121413Z","iopub.execute_input":"2025-11-15T16:41:47.121989Z","iopub.status.idle":"2025-11-15T16:41:47.136770Z","shell.execute_reply.started":"2025-11-15T16:41:47.121967Z","shell.execute_reply":"2025-11-15T16:41:47.136030Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def groq_generate(prompt):\n    response = client.chat.completions.create(\n        model=\"llama-3.1-8b-instant\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": (\n                    \"Kamu adalah teman ngobrol yang paham film. \"\n                    \"Gaya bicaramu santai, natural, tidak formal. \"\n                    \"Jawab hanya sesuai konteks yang diberikan. \"\n                    \"Kalau info tidak ada, bilang saja dengan santai.\"\n                )\n            },\n            {\n                \"role\": \"user\",\n                \"content\": prompt\n            }\n        ],\n        temperature=0.35,\n        max_tokens=400,\n    )\n    return response.choices[0].message.content","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T16:41:47.137384Z","iopub.execute_input":"2025-11-15T16:41:47.137591Z","iopub.status.idle":"2025-11-15T16:41:47.152671Z","shell.execute_reply.started":"2025-11-15T16:41:47.137578Z","shell.execute_reply":"2025-11-15T16:41:47.152055Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def lookup_exact_title(query):\n    q = normalize_title(query)\n\n    # cari judul yang paling mendekati exact\n    df_cleaned[\"norm_title\"] = df_cleaned[\"title\"].apply(normalize_title)\n\n    # exact match\n    exact = df_cleaned[df_cleaned[\"norm_title\"] == q]\n    if len(exact) == 0:\n        return None\n\n    row = exact.iloc[0]\n\n    # text = metadata + full plot\n    text = f\"\"\"\nTitle: {row['title']}\nYear: {row['year']}\nOrigin: {row['origin']}\nGenre: {row['genre']}\nDirector: {row['director']}\nCast: {row['cast']}\n\nPlot:\n{row['plot']}\n\"\"\".strip()\n\n    meta = {\n        \"title\": row[\"title\"],\n        \"year\": int(row[\"year\"]),\n        \"origin\": row[\"origin\"],\n        \"genre\": row[\"genre\"],\n        \"director\": row[\"director\"],\n        \"cast\": row[\"cast\"]\n    }\n\n    return {\"score\": 5.0, \"text\": text, \"meta\": meta}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T16:41:47.153290Z","iopub.execute_input":"2025-11-15T16:41:47.153494Z","iopub.status.idle":"2025-11-15T16:41:47.166535Z","shell.execute_reply.started":"2025-11-15T16:41:47.153471Z","shell.execute_reply":"2025-11-15T16:41:47.165866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def movie_chatbot(\n    query,\n    top_k_movies=5,\n    genre=None,\n    origin=None,\n    min_year=None,\n    max_year=None,\n    score_threshold=0.25\n):\n    q_words = query.strip().split()\n    if len(q_words) <= 3:        \n        exact = lookup_exact_title(query)\n        if exact is not None:\n            movies = [exact]\n            prompt = build_prompt(query, movies, web_context=None)\n            answer = groq_generate(prompt)\n            return answer, movies\n\n    movies = search_movies(\n        query=query,\n        top_k_movies=top_k_movies,\n        top_k_chunks=200,\n        genre=genre,\n        origin=origin,\n        min_year=min_year,\n        max_year=max_year,\n    )\n\n    movies = title_boost(query, movies)\n    movies = sorted(movies, key=lambda x: x[\"score\"], reverse=True)\n\n    best_score = movies[0][\"score\"] if movies else 0.0\n\n    web_ctx = None\n    if best_score < score_threshold:\n        web_ctx = web_search_serper(query)\n\n    prompt = build_prompt(query, movies, web_context=web_ctx)\n\n    answer = groq_generate(prompt)\n\n    return answer, movies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T16:41:47.167253Z","iopub.execute_input":"2025-11-15T16:41:47.167524Z","iopub.status.idle":"2025-11-15T16:41:47.184952Z","shell.execute_reply.started":"2025-11-15T16:41:47.167508Z","shell.execute_reply":"2025-11-15T16:41:47.184284Z"}},"outputs":[],"execution_count":null}]}